{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:15.072656Z",
     "iopub.status.busy": "2022-09-06T18:28:15.071886Z",
     "iopub.status.idle": "2022-09-06T18:28:15.097427Z",
     "shell.execute_reply": "2022-09-06T18:28:15.096348Z",
     "shell.execute_reply.started": "2022-09-06T18:28:15.072545Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:15.099770Z",
     "iopub.status.busy": "2022-09-06T18:28:15.099371Z",
     "iopub.status.idle": "2022-09-06T18:28:21.594001Z",
     "shell.execute_reply": "2022-09-06T18:28:21.592992Z",
     "shell.execute_reply.started": "2022-09-06T18:28:15.099733Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:21.597079Z",
     "iopub.status.busy": "2022-09-06T18:28:21.596109Z",
     "iopub.status.idle": "2022-09-06T18:28:21.830574Z",
     "shell.execute_reply": "2022-09-06T18:28:21.829559Z",
     "shell.execute_reply.started": "2022-09-06T18:28:21.597035Z"
    }
   },
   "outputs": [],
   "source": [
    "file=pd.read_fwf('../input/next-word/next_word_prediction.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:21.832307Z",
     "iopub.status.busy": "2022-09-06T18:28:21.831943Z",
     "iopub.status.idle": "2022-09-06T18:28:21.848721Z",
     "shell.execute_reply": "2022-09-06T18:28:21.847404Z",
     "shell.execute_reply.started": "2022-09-06T18:28:21.832273Z"
    }
   },
   "outputs": [],
   "source": [
    "file['Chapter 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:21.852018Z",
     "iopub.status.busy": "2022-09-06T18:28:21.851636Z",
     "iopub.status.idle": "2022-09-06T18:28:35.092097Z",
     "shell.execute_reply": "2022-09-06T18:28:35.091129Z",
     "shell.execute_reply.started": "2022-09-06T18:28:21.851983Z"
    }
   },
   "outputs": [],
   "source": [
    "# store file in list\n",
    "lines = []\n",
    "for i in file['Chapter 1']:\n",
    "    lines.append(i)\n",
    "\n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "    data = ' '. join(lines) \n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces \n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:35.098560Z",
     "iopub.status.busy": "2022-09-06T18:28:35.096369Z",
     "iopub.status.idle": "2022-09-06T18:28:35.666037Z",
     "shell.execute_reply": "2022-09-06T18:28:35.665110Z",
     "shell.execute_reply.started": "2022-09-06T18:28:35.098523Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:35.672598Z",
     "iopub.status.busy": "2022-09-06T18:28:35.670117Z",
     "iopub.status.idle": "2022-09-06T18:28:35.681654Z",
     "shell.execute_reply": "2022-09-06T18:28:35.680571Z",
     "shell.execute_reply.started": "2022-09-06T18:28:35.672554Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sequence_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:35.683867Z",
     "iopub.status.busy": "2022-09-06T18:28:35.683196Z",
     "iopub.status.idle": "2022-09-06T18:28:35.689817Z",
     "shell.execute_reply": "2022-09-06T18:28:35.688816Z",
     "shell.execute_reply.started": "2022-09-06T18:28:35.683832Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:35.692008Z",
     "iopub.status.busy": "2022-09-06T18:28:35.691207Z",
     "iopub.status.idle": "2022-09-06T18:28:36.111026Z",
     "shell.execute_reply": "2022-09-06T18:28:36.109949Z",
     "shell.execute_reply.started": "2022-09-06T18:28:35.691949Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:36.113045Z",
     "iopub.status.busy": "2022-09-06T18:28:36.112654Z",
     "iopub.status.idle": "2022-09-06T18:28:36.294689Z",
     "shell.execute_reply": "2022-09-06T18:28:36.293660Z",
     "shell.execute_reply.started": "2022-09-06T18:28:36.113010Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:36.298656Z",
     "iopub.status.busy": "2022-09-06T18:28:36.298269Z",
     "iopub.status.idle": "2022-09-06T18:28:36.307511Z",
     "shell.execute_reply": "2022-09-06T18:28:36.306568Z",
     "shell.execute_reply.started": "2022-09-06T18:28:36.298620Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:36.310374Z",
     "iopub.status.busy": "2022-09-06T18:28:36.309565Z",
     "iopub.status.idle": "2022-09-06T18:28:36.709467Z",
     "shell.execute_reply": "2022-09-06T18:28:36.708362Z",
     "shell.execute_reply.started": "2022-09-06T18:28:36.310336Z"
    }
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:36.711814Z",
     "iopub.status.busy": "2022-09-06T18:28:36.711488Z",
     "iopub.status.idle": "2022-09-06T18:28:40.192900Z",
     "shell.execute_reply": "2022-09-06T18:28:40.191732Z",
     "shell.execute_reply.started": "2022-09-06T18:28:36.711780Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:40.194488Z",
     "iopub.status.busy": "2022-09-06T18:28:40.194124Z",
     "iopub.status.idle": "2022-09-06T18:28:40.202382Z",
     "shell.execute_reply": "2022-09-06T18:28:40.201471Z",
     "shell.execute_reply.started": "2022-09-06T18:28:40.194433Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:40.204428Z",
     "iopub.status.busy": "2022-09-06T18:28:40.203830Z",
     "iopub.status.idle": "2022-09-06T18:28:41.247333Z",
     "shell.execute_reply": "2022-09-06T18:28:41.246148Z",
     "shell.execute_reply.started": "2022-09-06T18:28:40.204387Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:28:41.250034Z",
     "iopub.status.busy": "2022-09-06T18:28:41.249045Z",
     "iopub.status.idle": "2022-09-06T18:31:22.619392Z",
     "shell.execute_reply": "2022-09-06T18:31:22.617487Z",
     "shell.execute_reply.started": "2022-09-06T18:28:41.249993Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=5, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:31:22.622989Z",
     "iopub.status.busy": "2022-09-06T18:31:22.622495Z",
     "iopub.status.idle": "2022-09-06T18:31:23.771462Z",
     "shell.execute_reply": "2022-09-06T18:31:23.770480Z",
     "shell.execute_reply.started": "2022-09-06T18:31:22.622957Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "  \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "  \n",
    "  print(predicted_word)\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T18:35:01.972296Z",
     "iopub.status.busy": "2022-09-06T18:35:01.971904Z",
     "iopub.status.idle": "2022-09-06T18:36:10.405927Z",
     "shell.execute_reply": "2022-09-06T18:36:10.404794Z",
     "shell.execute_reply.started": "2022-09-06T18:35:01.972264Z"
    }
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "  \n",
    "  if text == \"0\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "  \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "        \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "          \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
